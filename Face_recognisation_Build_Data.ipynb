{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection - Build Data for new user\n",
    "Computer Vision: Real Time live image capture with demographic details \n",
    "The purpose of this python code is to capture basic demographic details and capture 50 faces of each user to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings  \n",
    "import os\n",
    " \n",
    "warnings.filterwarnings('ignore')\n",
    "import tkinter as tk\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Emotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/sriha/Desktop/fr/'\n",
    "os.environ['OPENCV_VIDEOIO_PRIORITY_MSMF'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routine to capture face features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(path + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)          # Convert from RGB to GRAY\n",
    "    \n",
    "    #Search the co-ordinates of the image\n",
    "    faces = face_classifier.detectMultiScale(gray,scaleFactor=1.3,minNeighbors =5) \n",
    "\n",
    "    if faces is():       # No faces\n",
    "        return None\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        \n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.remove('employee.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 1:  Capature basic demographic details such as Name, Gender and ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entry_fields():\n",
    "    \n",
    "    NAME_.append(e1.get())  \n",
    "    NAME_.append(e2.get())\n",
    "\n",
    "def combine_funcs(*funcs):\n",
    "    def combined_func(*args, **kwargs):\n",
    "        for f in funcs:\n",
    "            f(*args, **kwargs)\n",
    "    return combined_func\n",
    "\n",
    "def add_gender():\n",
    "    \n",
    "    temp = selected.get()\n",
    "    \n",
    "    if (temp == 1):\n",
    "        NAME_.append('Male')\n",
    "    else:\n",
    "        NAME_.append('Female')\n",
    "        \n",
    "        \n",
    "window = tk.Tk()\n",
    "window.title(\"Welcome to Employee Add Menu\")\n",
    "window.geometry('550x250')\n",
    "NAME_   = []\n",
    "GENDER_ = []\n",
    "\n",
    "tk.Label(window, text=\"Name\",fg=\"blue\",font=\"lucida 10 bold\").grid(row=0)\n",
    "tk.Label(window, text=\"    ID\",fg=\"blue\",font=\"lucida 10 bold\").grid(row=1)\n",
    "tk.Label(window, text=\"Gender   \",fg=\"blue\",font=\"lucida 10 bold\").grid(row=2)\n",
    "\n",
    "e1 = tk.Entry(window)\n",
    "e2 = tk.Entry(window)\n",
    "\n",
    "selected = tk.IntVar()\n",
    "selected.set(2)\n",
    "e3 = tk.Radiobutton(window,text='Male', variable = selected,value=1,command = add_gender)\n",
    "e4 = tk.Radiobutton(window,text='Female', variable = selected,value=2,command = add_gender)\n",
    "\n",
    "\n",
    "e1.grid(row=0, column=1)\n",
    "e2.grid(row=1, column=1)\n",
    "e3.grid(row=2, column=1)\n",
    "e4.grid(row=2, column=2)\n",
    "\n",
    "tk.Button(window, \n",
    "          text='Quit',bg=\"blue\", fg=\"white\",font=(\"Arial Bold\", 13),\n",
    "          command=window.destroy).grid(row=13,\n",
    "                                    column=1, \n",
    "                                    sticky=tk.W, \n",
    "                                    pady=4)\n",
    "\n",
    "tk.Button(window, \n",
    "          text='Submit', bg=\"blue\", fg=\"white\",font=(\"Arial Bold\", 13),\n",
    "                         command=combine_funcs(save_entry_fields,window.destroy)).grid(row=13, \n",
    "                                                       column=2, \n",
    "                                                       sticky=tk.W, \n",
    "                                                       pady=4)\n",
    "  \n",
    "\n",
    "tk.mainloop()\n",
    "\n",
    "Gender   = pd.DataFrame([NAME_[0]],columns= ['Gender'])\n",
    "Name     = pd.DataFrame([NAME_[1]],columns= ['Name'])\n",
    "ID       = pd.DataFrame([NAME_[2]],columns= ['ID'])\n",
    "df       = pd.concat([ID,Name,Gender],axis=1)\n",
    "\n",
    "################\n",
    "# Append to CSV\n",
    "################\n",
    "\n",
    "#df.to_csv('employee.csv',mode='a', header=True)\n",
    "df.to_csv('employee.csv', mode='a', header=False) \n",
    "\n",
    "\n",
    "ID_     = NAME_[2]\n",
    "\n",
    "#del df\n",
    "#del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase  2:  Capture and save the image (50 different faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save face images and show the images\n",
    "\n",
    "video = cv2.VideoCapture(0)  # 0 to specify to use built-in camera\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count+=1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        file_name_path = path + 'Images/'+ID_ + '_'+ str(count)+'.jpg'   # Save images in .jpg format\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        cv2.putText(face, str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Face Cropper',face)\n",
    "    else:\n",
    "        #print(\"Face not Found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1)==13 or count==50: # 13 is ASCII code for Enter Key or Maximum of 50 images\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Collecting Samples Completed...........')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 3: Train the model  by assigning label starting from 1 to 50 with ID as prefix for each encoded face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = path + 'Images/'\n",
    "Training_Data, Labels, onlylabels = [], [] , []\n",
    "\n",
    "onlylabels = [f for f in listdir(imgs_path) if isfile(join(imgs_path ,f))]\n",
    "\n",
    "for i, files in enumerate(onlylabels):\n",
    "    image_path = imgs_path + onlylabels[i]\n",
    "    images     = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(onlylabels[i])\n",
    "\n",
    "# Extract only numerics from string\n",
    "Labels = list(map(lambda sub:int(''.join( \n",
    "          [ele for ele in sub if ele.isnumeric()])), Labels)) \n",
    "\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "model  = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    " \n",
    "print(\"Model Training Complete!!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write(path + \"data_model.yml\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## End of the Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
