{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Face Detection\n",
    "Computer Vision: Real Time live image capture, detect image from the trained dataset and show basic demographic details with name and emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings  \n",
    "import os\n",
    "import pendulum\n",
    "warnings.filterwarnings('ignore')\n",
    "import tkinter as tkhttp \n",
    "import cv2\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from wide_resnet import WideResNet\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Emotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/sriha/Desktop/'\n",
    "\n",
    "modelEmo = model_from_json(open(path + \"Emotion_Analysis.json\", \"r\").read())\n",
    "modelEmo.load_weights(path + \"Emotion_Analysis.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE_PATH = path + 'haarcascade_frontalface_default.xml'\n",
    "os.environ['OPENCV_VIDEOIO_PRIORITY_MSMF'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load known face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(path + \"data_model.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routine to detect the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(img, size = 0.5):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)          # Convert from RGB to GRAY\n",
    "    \n",
    "    #Search the co-ordinates of the image\n",
    "    faces = face_classifier.detectMultiScale(gray,scaleFactor=1.3,minNeighbors =5) \n",
    "\n",
    "    if faces is():         # No faces / No-Match\n",
    "        return img,[]\n",
    "    \n",
    "    for(x,y,w,h) in faces: # Match\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)   \n",
    "     \n",
    "    # Get face and resize\n",
    "        face_img  = img[y:y+h, x:x+w]\n",
    "        face_img  = cv2.resize(face_img, (48,48))\n",
    "\n",
    "    return img,face_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routine to fetch the user name with face emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_name(id,face):\n",
    "     \n",
    "    temp = str(id)\n",
    "    temp = int(temp[:3])\n",
    "    ################################################# \n",
    "    # Read CSV file to fetch the name of the employee \n",
    "    #################################################    \n",
    "     \n",
    "    data = pd.DataFrame()\n",
    "    os.chdir(path)\n",
    "    data = pd.read_csv(\"employee.csv\")\n",
    "    data.drop('Unnamed: 0', axis = 1 , inplace= True)\n",
    "    data= data.sort_values('ID')\n",
    "    \n",
    "    # Fetch employee name\n",
    "\n",
    "    name = data.loc[data['ID'] == temp]\n",
    "    name = name['Name'].iloc[0]\n",
    "    \n",
    "    ######################### \n",
    "    # Get the face emotion \n",
    "    #########################\n",
    "     \n",
    "    gray_img       = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "    faces_detected = face_classifier.detectMultiScale(gray_img, 1.32, 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        \n",
    "        #cv2.rectangle(face,(x,y),(x+w,y+h),(255,0,0))\n",
    "        face_img    = gray_img[y:y+w,x:x+h]      #cropping region of interest i.e. face area from  image\n",
    "        face_img    = cv2.resize(face_img,(48,48))\n",
    "        img_pixels  = image.img_to_array(face_img)\n",
    "        img_pixels  = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "        pred        = modelEmo.predict(np.array(img_pixels))\n",
    "        index       = np.argmax(pred[0])\n",
    "        \n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "        pred_emo = emotions[index]\n",
    "        \n",
    "        return name, temp, pred_emo , x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the unknown live image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(CASE_PATH)\n",
    "\n",
    "video = cv2.VideoCapture(0)  # Read the image from camera\n",
    "match = 'N'\n",
    "\n",
    "while True:\n",
    "     \n",
    "    ret, img_frame  = video.read()  # captures frame and returns boolean value and captured image\n",
    "    image_, face    = face_detector(img_frame)\n",
    "             \n",
    "    try:\n",
    "        # Reading the image as gray scale image\n",
    "        face   = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result = recognizer.predict(face)\n",
    "        \n",
    "        if result[1] < 500:\n",
    "            confidence          = int(100*(1-(result[1])/300))\n",
    "            user,empid,emo,h,w  = get_user_name(str(result[0]),img_frame)\n",
    "            display_string      = user \n",
    "        \n",
    "        cv2.putText(image_,display_string,(2,50), cv2.FONT_HERSHEY_SIMPLEX,1,(150,100,200),2)\n",
    "        cv2.putText(image_,'EmpId=' + str(empid),(2,85), cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),2)\n",
    "        cv2.putText(image_,pendulum.now().to_day_datetime_string(),(370,80), cv2.FONT_HERSHEY_PLAIN,1,(0, 0, 0),2)\n",
    "        \n",
    "        cv2.putText(image_,emo,(int(h)+10,int(w)-15), cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "        \n",
    "        resized_img = cv2.resize(image_, (1600, 960))\n",
    "        cv2.imshow('Face Cropper', resized_img)\n",
    "        match = 'Y'\n",
    "    \n",
    "    except:\n",
    "        cv2.putText(image_, \"Face Not Found\", (250, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        resized_img = cv2.resize(image_, (1600, 960))\n",
    "        cv2.imshow('Face Cropper', resized_img)\n",
    "        match = 'N'\n",
    "        #img_frame = ''\n",
    "        pass\n",
    "\n",
    "    if (cv2.waitKey(1)==13):   # 13 is ASCII code for Enter Key\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## End of the Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
